{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from time import clock\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics import adjusted_mutual_info_score, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajmot\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "dataset1_csv = pd.read_csv('march_madness.csv')\n",
    "\n",
    "game_result = dataset1_csv.values[:,3] - dataset1_csv.values[:,20]\n",
    "basketball = {\n",
    "    \"data\": np.delete(dataset1_csv.values, [0,2,3,19,20], axis=1),\n",
    "    \"target\": np.vectorize(lambda x : 0 if x < 1 else 1)(game_result)\n",
    "}\n",
    "encoder=LabelEncoder()\n",
    "for idx in range(len(basketball[\"data\"][0])):\n",
    "    if type(basketball[\"data\"][0][idx]) is str:\n",
    "        basketball[\"data\"][:,idx]=encoder.fit_transform(basketball[\"data\"][:,idx])\n",
    "\n",
    "basketball[\"data\"] = StandardScaler().fit_transform(basketball[\"data\"])\n",
    "    \n",
    "digits = load_digits()\n",
    "digit = {\n",
    "    \"data\": StandardScaler().fit_transform(digits.data),\n",
    "    \"target\": digits.target\n",
    "}\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import pandas as pd\n",
    "\n",
    "# dataset1_csv = pd.read_csv('binary_basketball.csv')\n",
    "# initial_dataset = dataset1_csv.values\n",
    "\n",
    "# # March Madness \n",
    "# game_result = dataset1_csv.values[:,41]\n",
    "\n",
    "# initial_dataset = dataset1_csv.values\n",
    "# updated_dataset = np.copy(dataset1_csv.values)\n",
    "# basketball = {\n",
    "#     \"data\": np.delete(updated_dataset, [41], axis=1),\n",
    "#     \"target\": np.vectorize(lambda x : 0 if x == \"Away\" else 1)(game_result)\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_mutual_info_score, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "def cluster_acc(Y,clusterLabels):\n",
    "    assert (Y.shape == clusterLabels.shape)\n",
    "    pred = np.empty_like(Y)\n",
    "    for label in set(clusterLabels):\n",
    "        mask = clusterLabels == label\n",
    "        sub = Y[mask]\n",
    "        target = Counter(sub).most_common(1)[0][0]\n",
    "        pred[mask] = target\n",
    "    return accuracy_score(Y,pred)\n",
    "\n",
    "kValues = [2, 4, 6, 8, 10, 12, 14, 20, 40, 60, 80, 100]\n",
    "\n",
    "def runKMeansClustering(data, target, filePrefix, printCenters=False):\n",
    "    print(filePrefix + \" KMeans\")\n",
    "    results = {\n",
    "        \"accuracy\": [],\n",
    "        \"ami\": [],\n",
    "        \"score\": []\n",
    "    }\n",
    "    \n",
    "    for k in kValues:\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        kmeans.fit(data)\n",
    "        accuracy = cluster_acc(target, kmeans.predict(data))\n",
    "        ami = adjusted_mutual_info_score(target, kmeans.predict(data))\n",
    "        results[\"accuracy\"].append(accuracy)\n",
    "        results[\"ami\"].append(ami)\n",
    "        results[\"score\"].append(kmeans.score(data))\n",
    "        if printCenters:\n",
    "            tmp = pd.DataFrame(np.std(kmeans.cluster_centers_, axis=0))\n",
    "            tmp.to_csv(str(k)+filePrefix+'_kmeans_centers.csv')\n",
    "            \n",
    "    tmp = pd.DataFrame(list(zip(kValues, results[\"accuracy\"])))\n",
    "    tmp.to_csv(filePrefix + '_kmeans_accuracy.csv')\n",
    "    \n",
    "    tmp = pd.DataFrame(list(zip(kValues, results[\"ami\"])))\n",
    "    tmp.to_csv(filePrefix + '_kmeans_ami.csv')\n",
    "    \n",
    "    tmp = pd.DataFrame(list(zip(kValues, results[\"score\"])))\n",
    "    tmp.to_csv(filePrefix + '_kmeans_log_likelihood.csv')\n",
    "    \n",
    "def runGMMClustering(data, target, filePrefix, printCenters=False):\n",
    "    print(filePrefix + \" GMM\")\n",
    "    results = {\n",
    "        \"accuracy\": [],\n",
    "        \"ami\": [],\n",
    "        \"score\": []\n",
    "    }\n",
    "    \n",
    "    for k in kValues:\n",
    "        gmm = GMM(n_components=k)\n",
    "        gmm.fit(data)\n",
    "        accuracy = cluster_acc(target, gmm.predict(data))\n",
    "        ami = adjusted_mutual_info_score(target, gmm.predict(data))\n",
    "        results[\"accuracy\"].append(accuracy)\n",
    "        results[\"ami\"].append(ami)\n",
    "        results[\"score\"].append(gmm.score(data))\n",
    "        if printCenters:\n",
    "            tmp = pd.DataFrame(np.std(gmm.means_, axis=0))\n",
    "            tmp.to_csv(str(k)+filePrefix+'_gmm_centers.csv')\n",
    "            \n",
    "    tmp = pd.DataFrame(list(zip(kValues, results[\"accuracy\"])))\n",
    "    tmp.to_csv(filePrefix + '_gmm_accuracy.csv')\n",
    "    \n",
    "    tmp = pd.DataFrame(list(zip(kValues, results[\"ami\"])))\n",
    "    tmp.to_csv(filePrefix + '_gmm_ami.csv')\n",
    "    \n",
    "    tmp = pd.DataFrame(list(zip(kValues, results[\"score\"])))\n",
    "    tmp.to_csv(filePrefix + '_gmm_sse.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means Clustering and EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basketball KMeans\n",
      "basketball GMM\n",
      "digit KMeans\n",
      "digit GMM\n"
     ]
    }
   ],
   "source": [
    "runKMeansClustering(basketball[\"data\"], basketball[\"target\"], \"basketball\", printCenters=True)\n",
    "runGMMClustering(basketball[\"data\"], basketball[\"target\"], \"basketball\", printCenters=True)\n",
    "runKMeansClustering(digit[\"data\"], digit[\"target\"], \"digit\", printCenters=True)\n",
    "runGMMClustering(digit[\"data\"], digit[\"target\"], \"digit\", printCenters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "def reconstructionError(transformer,data):\n",
    "    X_train = transformer.transform(data)\n",
    "    X_projected = transformer.inverse_transform(X_train)\n",
    "    return ((data - X_projected) ** 2).mean()\n",
    "\n",
    "def reconstructionErrorRP(projections,X):\n",
    "    W = projections.components_\n",
    "    if sps.issparse(W):\n",
    "        W = W.todense()\n",
    "    p = pinv(W)\n",
    "    reconstructed = ((p@W)@(X.T)).T # Unproject projected data\n",
    "    errors = np.square(X-reconstructed)\n",
    "    return np.nanmean(errors)\n",
    "\n",
    "def pairwiseDistCorr(X1,X2):\n",
    "    assert X1.shape[0] == X2.shape[0]\n",
    "    \n",
    "    d1 = pairwise_distances(X1)\n",
    "    d2 = pairwise_distances(X2)\n",
    "    return np.corrcoef(d1.ravel(),d2.ravel())[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca_basketball_2 KMeans\n",
      "pca_basketball_2 GMM\n",
      "pca_basketball_4 KMeans\n",
      "pca_basketball_4 GMM\n",
      "pca_basketball_10 KMeans\n",
      "pca_basketball_10 GMM\n",
      "pca_basketball_20 KMeans\n",
      "pca_basketball_20 GMM\n",
      "pca_basketball_30 KMeans\n",
      "pca_basketball_30 GMM\n",
      "pca_basketball_35 KMeans\n",
      "pca_basketball_35 GMM\n",
      "pca_digit_2 KMeans\n",
      "pca_digit_2 GMM\n",
      "pca_digit_4 KMeans\n",
      "pca_digit_4 GMM\n",
      "pca_digit_10 KMeans\n",
      "pca_digit_10 GMM\n",
      "pca_digit_20 KMeans\n",
      "pca_digit_20 GMM\n",
      "pca_digit_30 KMeans\n",
      "pca_digit_30 GMM\n",
      "pca_digit_40 KMeans\n",
      "pca_digit_40 GMM\n",
      "pca_digit_50 KMeans\n",
      "pca_digit_50 GMM\n",
      "pca_digit_60 KMeans\n",
      "pca_digit_60 GMM\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "reconstructionErrors = []\n",
    "explainedVariances = []\n",
    "dims_bb = [2,4,10,20,30,35]\n",
    "for dim in dims_bb:\n",
    "    pca = PCA(n_components=dim)\n",
    "    pca.fit(basketball[\"data\"])\n",
    "    \n",
    "    explainedVariances.append(pca.explained_variance_)\n",
    "    reconstruction = reconstructionError(pca, basketball[\"data\"])\n",
    "    reconstructionErrors.append(reconstruction)\n",
    "    \n",
    "    pcaBasketballData = pca.fit_transform(basketball[\"data\"])\n",
    "    runKMeansClustering(pcaBasketballData, basketball[\"target\"], \"pca_basketball_\" + str(dim))\n",
    "    runGMMClustering(pcaBasketballData, basketball[\"target\"], \"pca_basketball_\" + str(dim))\n",
    "\n",
    "tmp = pd.DataFrame(list(zip(dims_bb, explainedVariances)))\n",
    "tmp.to_csv('pca_basketball_explained_variances.csv')\n",
    "\n",
    "tmp = pd.DataFrame(list(zip(dims_bb, reconstructionErrors)))\n",
    "tmp.to_csv('pca_basketball_reconstruction_error.csv')\n",
    "\n",
    "reconstructionErrors = []\n",
    "explainedVariances = []\n",
    "dims_digit = [2,4,10,20,30,40,50,60]\n",
    "for dim in dims_digit:\n",
    "    pca = PCA(n_components=dim)\n",
    "    pca.fit(digit[\"data\"])\n",
    "    \n",
    "    explainedVariances.append(pca.explained_variance_)\n",
    "    reconstruction = reconstructionError(pca, digit[\"data\"])\n",
    "    reconstructionErrors.append(reconstruction)\n",
    "    \n",
    "    pcadigitData = pca.fit_transform(digit[\"data\"])\n",
    "    runKMeansClustering(pcadigitData, digit[\"target\"], \"pca_digit_\" + str(dim))\n",
    "    runGMMClustering(pcadigitData, digit[\"target\"], \"pca_digit_\" + str(dim))\n",
    "\n",
    "tmp = pd.DataFrame(list(zip(dims_digit, explainedVariances)))\n",
    "tmp.to_csv('pca_digit_explained_variances.csv')\n",
    "\n",
    "tmp = pd.DataFrame(list(zip(dims_digit, reconstructionErrors)))\n",
    "tmp.to_csv('pca_digit_reconstruction_error.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ica_basketball_2 KMeans\n",
      "ica_basketball_2 GMM\n",
      "ica_basketball_4 KMeans\n",
      "ica_basketball_4 GMM\n",
      "ica_basketball_10 KMeans\n",
      "ica_basketball_10 GMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajmot\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\fastica_.py:118: UserWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn('FastICA did not converge. Consider increasing '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ica_basketball_20 KMeans\n",
      "ica_basketball_20 GMM\n",
      "ica_basketball_30 KMeans\n",
      "ica_basketball_30 GMM\n",
      "ica_basketball_35 KMeans\n",
      "ica_basketball_35 GMM\n",
      "ica_digit_2 KMeans\n",
      "ica_digit_2 GMM\n",
      "ica_digit_4 KMeans\n",
      "ica_digit_4 GMM\n",
      "ica_digit_10 KMeans\n",
      "ica_digit_10 GMM\n",
      "ica_digit_20 KMeans\n",
      "ica_digit_20 GMM\n",
      "ica_digit_30 KMeans\n",
      "ica_digit_30 GMM\n",
      "ica_digit_40 KMeans\n",
      "ica_digit_40 GMM\n",
      "ica_digit_50 KMeans\n",
      "ica_digit_50 GMM\n",
      "ica_digit_60 KMeans\n",
      "ica_digit_60 GMM\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "reconstructionErrors = []\n",
    "kurtosis = []\n",
    "dims_bb = [2,4,10,20,30,35]\n",
    "for dim in dims_bb:\n",
    "    ica = FastICA(n_components=dim)\n",
    "    ica.fit(basketball[\"data\"])\n",
    "    \n",
    "    reconstruction = reconstructionError(ica, basketball[\"data\"])\n",
    "    reconstructionErrors.append(reconstruction)\n",
    "    \n",
    "    icaBasketballData = ica.fit_transform(basketball[\"data\"])\n",
    "    \n",
    "    tmp = pd.DataFrame(icaBasketballData)\n",
    "    tmp = tmp.kurt(axis=0)\n",
    "    kurtosis.append(tmp.abs().mean())\n",
    "    \n",
    "    runKMeansClustering(icaBasketballData, basketball[\"target\"], \"ica_basketball_\" + str(dim))\n",
    "    runGMMClustering(icaBasketballData, basketball[\"target\"], \"ica_basketball_\" + str(dim))\n",
    "\n",
    "tmp = pd.DataFrame(list(zip(dims_bb, kurtosis)))\n",
    "tmp.to_csv('ica_basketball_kurtosis.csv')\n",
    "\n",
    "tmp = pd.DataFrame(list(zip(dims_bb, reconstructionErrors)))\n",
    "tmp.to_csv('ica_basketball_reconstruction_error.csv')\n",
    "\n",
    "reconstructionErrors = []\n",
    "kurtosis = []\n",
    "dims_digit = [2,4,10,20,30,40,50,60]\n",
    "for dim in dims_digit:\n",
    "    ica = FastICA(n_components=dim)\n",
    "    ica.fit(digit[\"data\"])\n",
    "    \n",
    "    reconstruction = reconstructionError(ica, digit[\"data\"])\n",
    "    reconstructionErrors.append(reconstruction)\n",
    "    \n",
    "    icadigitData = ica.fit_transform(digit[\"data\"])\n",
    "    \n",
    "    tmp = pd.DataFrame(icadigitData)\n",
    "    tmp = tmp.kurt(axis=0)\n",
    "    kurtosis.append(tmp.abs().mean())\n",
    "    \n",
    "    runKMeansClustering(icadigitData, digit[\"target\"], \"ica_digit_\" + str(dim))\n",
    "    runGMMClustering(icadigitData, digit[\"target\"], \"ica_digit_\" + str(dim))\n",
    "\n",
    "tmp = pd.DataFrame(list(zip(dims_digit, kurtosis)))\n",
    "tmp.to_csv('ica_digit_kurtosis.csv')\n",
    "\n",
    "tmp = pd.DataFrame(list(zip(dims_digit, reconstructionErrors)))\n",
    "tmp.to_csv('ica_digit_reconstruction_error.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Random Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from itertools import product\n",
    "\n",
    "# # reconstructionErrors = defaultdict(list)\n",
    "# pairwise_distance_correlation = defaultdict(list)\n",
    "# dims_bb = [2,4,10,20,30,35]\n",
    "# for i in range(10):\n",
    "#     for dim in dims_bb:\n",
    "#         rp = SparseRandomProjection(random_state=i, n_components=dim)\n",
    "#         rp.fit(basketball[\"data\"])\n",
    "\n",
    "#         rpBasketballData = rp.fit_transform(basketball[\"data\"])\n",
    "\n",
    "#         pairwise_distance_correlation[dim].append(pairwiseDistCorr(rpBasketballData, basketball[\"data\"]))\n",
    "\n",
    "#         runKMeansClustering(rpBasketballData, basketball[\"target\"], \"rp_basketball_\" + str(dim) + \"_\" + str(i))\n",
    "#         runGMMClustering(rpBasketballData, basketball[\"target\"], \"rp_basketball_\" + str(dim) + \"_\" + str(i))\n",
    "\n",
    "# tmp = pd.DataFrame(pairwise_distance_correlation)\n",
    "# tmp.to_csv('rp_basketball_pairwise_dist_corr.csv')\n",
    "\n",
    "# tmp = pd.DataFrame(reconstructionErrors)\n",
    "# tmp.to_csv('rp_basketball_reconstruction_error.csv')\n",
    "\n",
    "# reconstructionErrors = defaultdict(list)\n",
    "pairwise_distance_correlation = defaultdict(list)\n",
    "dims_digit = [2,4,10,20,30,40,50,60]\n",
    "for i in range(10):\n",
    "    for dim in dims_digit:\n",
    "        rp = SparseRandomProjection(random_state=i, n_components=dim)\n",
    "        rp.fit(digit[\"data\"])\n",
    "\n",
    "    #     reconstruction = reconstructionErrorRP(rp, digit[\"data\"])\n",
    "    #     reconstructionErrors[i].append(reconstruction)\n",
    "\n",
    "        rpDigitData = rp.fit_transform(digit[\"data\"])\n",
    "\n",
    "        pairwise_distance_correlation[dim].append(pairwiseDistCorr(rpDigitData, digit[\"data\"]))\n",
    "\n",
    "#         runKMeansClustering(rpDigitData, digit[\"target\"], \"rp_digit_\" + str(dim) + \"_\" + str(i))\n",
    "#         runGMMClustering(rpDigitData, digit[\"target\"], \"rp_digit_\" + str(dim) + \"_\" + str(i))\n",
    "\n",
    "tmp = pd.DataFrame(pairwise_distance_correlation)\n",
    "tmp.to_csv('rp_digit_pairwise_dist_corr.csv')\n",
    "\n",
    "# tmp = pd.DataFrame(reconstructionErrors)\n",
    "# tmp.to_csv('rp_digit_reconstruction_error.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Random Forest Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc_basketball_ KMeans\n",
      "rfc_basketball_ GMM\n",
      "rfc_digit_10_ KMeans\n",
      "rfc_digit_10_ GMM\n",
      "rfc_digit_15_ KMeans\n",
      "rfc_digit_15_ GMM\n",
      "rfc_digit_20_ KMeans\n",
      "rfc_digit_20_ GMM\n",
      "rfc_digit_25_ KMeans\n",
      "rfc_digit_25_ GMM\n",
      "rfc_digit_30_ KMeans\n",
      "rfc_digit_30_ GMM\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "\n",
    "class ImportanceSelect(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, n=1):\n",
    "         self.model = model\n",
    "         self.n = n\n",
    "    def fit(self, *args, **kwargs):\n",
    "         self.model.fit(*args, **kwargs)\n",
    "         return self\n",
    "    def transform(self, X):\n",
    "         return X[:,self.model.feature_importances_.argsort()[::-1][:self.n]]\n",
    "\n",
    "        \n",
    "rfc = RandomForestClassifier(n_estimators=100,class_weight='balanced',n_jobs=7)\n",
    "fs_bball = rfc.fit(basketball[\"data\"], basketball[\"target\"]).feature_importances_ \n",
    "rfcBasketballData = ImportanceSelect(rfc, 10).fit_transform(basketball[\"data\"], basketball[\"target\"])\n",
    "\n",
    "tmp = pd.Series(fs_bball)\n",
    "tmp.to_csv(\"rfc_basketball_feature_importance.csv\")\n",
    "\n",
    "runKMeansClustering(rfcBasketballData, basketball[\"target\"], \"rfc_basketball_\")\n",
    "runGMMClustering(rfcBasketballData, basketball[\"target\"], \"rfc_basketball_\")\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100,class_weight='balanced',n_jobs=7)\n",
    "fs_digit = rfc.fit(digit[\"data\"], digit[\"target\"]).feature_importances_ \n",
    "for i in [10, 15, 20, 25, 30]:    \n",
    "    rfcDigitData = ImportanceSelect(rfc, i).fit_transform(digit[\"data\"], digit[\"target\"])\n",
    "\n",
    "#     tmp = pd.Series(fs_digit)\n",
    "#     tmp.to_csv(\"rfc_digit_feature_importance.csv\")\n",
    "\n",
    "    runKMeansClustering(rfcDigitData, digit[\"target\"], \"rfc_digit_\" + str(i) + \"_\")\n",
    "    runGMMClustering(rfcDigitData, digit[\"target\"], \"rfc_digit_\" + str(i) + \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
